{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T20:55:27.065048Z",
     "start_time": "2018-07-16T20:55:26.860842Z"
    }
   },
   "outputs": [],
   "source": [
    "# import\n",
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T14:57:19.075282Z",
     "start_time": "2018-07-16T14:57:18.992190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5485, 2)\n",
      "(2189, 2)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"data/r8-train-all-terms.txt\", header=None, sep=\"\\t\")\n",
    "test = pd.read_csv(\"data/r8-test-all-terms.txt\", header=None, sep=\"\\t\")\n",
    "train.columns = [\"label\", \"content\"]\n",
    "test.columns = [\"label\", \"content\"]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T15:05:04.852147Z",
     "start_time": "2018-07-16T15:05:04.835289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earn</td>\n",
       "      <td>champion products ch approves stock split cham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acq</td>\n",
       "      <td>computer terminal systems cpml completes sale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earn</td>\n",
       "      <td>cobanco inc cbco year net shr cts vs dlrs net ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earn</td>\n",
       "      <td>am international inc am nd qtr jan oper shr lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earn</td>\n",
       "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            content\n",
       "0  earn  champion products ch approves stock split cham...\n",
       "1   acq  computer terminal systems cpml completes sale ...\n",
       "2  earn  cobanco inc cbco year net shr cts vs dlrs net ...\n",
       "3  earn  am international inc am nd qtr jan oper shr lo...\n",
       "4  earn  brown forman inc bfd th qtr net shr one dlr vs..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T15:14:27.740019Z",
     "start_time": "2018-07-16T15:14:27.735374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['earn', 'acq', 'trade', 'ship', 'grain', 'crude', 'interest',\n",
       "       'money-fx'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T15:06:15.390341Z",
     "start_time": "2018-07-16T15:06:15.377459Z"
    }
   },
   "outputs": [],
   "source": [
    "# glove vectorizer\n",
    "class GloveVectorizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Loading word vectors\")\n",
    "        \n",
    "        word2vec = {}\n",
    "        embedding = []\n",
    "        idx2word = []\n",
    "        \n",
    "        with open(\"embeddings/glove.6B.50d.txt\") as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vec = np.asarray(values[1:], dtype=float)\n",
    "                word2vec[word] = vec\n",
    "                embedding.append(vec)\n",
    "                idx2word.append(word)\n",
    "            print(\"Loaded %s words\" % len(word2vec))\n",
    "        \n",
    "        self.word2vec = word2vec\n",
    "        self.embedding = np.array(embedding)\n",
    "        self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
    "        self.V, self.D = self.embedding.shape\n",
    "        \n",
    "        \n",
    "    def fit(self, data):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def transform(self, data):\n",
    "        # convert sentence to average of word2vec vectors\n",
    "        \n",
    "        X = np.zeros((len(data), self.D))\n",
    "        n = 0\n",
    "        emptycount = 0\n",
    "        \n",
    "        for sentence in data:\n",
    "            tokens = sentence.lower().split()\n",
    "            vecs = []\n",
    "            for word in tokens:\n",
    "                if word in self.word2vec:\n",
    "                    vec = self.word2vec[word]\n",
    "                    vecs.append(vec)\n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                X[n] = vecs.mean(axis=0)\n",
    "            else:\n",
    "                emptycount += 1\n",
    "            n += 1\n",
    "        print(\"Number of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T15:11:37.774679Z",
     "start_time": "2018-07-16T15:11:37.767483Z"
    }
   },
   "outputs": [],
   "source": [
    "# w2v vectorizer\n",
    "class Word2VecVectorizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Loading word vectors\")\n",
    "        \n",
    "        self.word_vectors = KeyedVectors.load_word2vec_format(\"embeddings/GoogleNews-vectors-negative300.bin\", \n",
    "                                                              binary=True)\n",
    "        print(\"Finished loading word vectors\")\n",
    "        \n",
    "        \n",
    "    def fit(self, data):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def transform(self, data):\n",
    "        # convert sentence to average of word2vec vectors\n",
    "        \n",
    "        v = self.word_vectors.get_vector(\"king\")\n",
    "        self.D = v.shape[0]\n",
    "        \n",
    "        X = np.zeros((len(data), self.D))\n",
    "        n = 0\n",
    "        emptycount = 0\n",
    "        \n",
    "        for sentence in data:\n",
    "            tokens = sentence.split() # no lower since w2v contains capital chars\n",
    "            vecs = []\n",
    "            m = 0\n",
    "            for word in tokens:\n",
    "                try:\n",
    "                    vec = self.word_vectors.get_vector(word) # throws KeyError if not found\n",
    "                    vecs.append(vec)\n",
    "                    m += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                X[m] = vecs.mean(axis=0)\n",
    "            else:\n",
    "                emptycount += 1\n",
    "            n += 1\n",
    "        print(\"Number of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T15:12:34.313398Z",
     "start_time": "2018-07-16T15:11:41.393477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors\n",
      "Finished loading word vectors\n"
     ]
    }
   ],
   "source": [
    "# initialize vectorizer\n",
    "vectorizer = Word2VecVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T15:12:35.785593Z",
     "start_time": "2018-07-16T15:12:34.315769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with no words found: 0 / 5485\n"
     ]
    }
   ],
   "source": [
    "# fit transform train data\n",
    "Xtrain = vectorizer.fit_transform(train.content)\n",
    "Ytrain = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T15:12:36.325508Z",
     "start_time": "2018-07-16T15:12:35.787519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with no words found: 0 / 2189\n"
     ]
    }
   ],
   "source": [
    "# transform test data\n",
    "Xtest = vectorizer.transform(test.content)\n",
    "Ytest = test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T16:02:46.558403Z",
     "start_time": "2018-07-16T16:02:45.444142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fitting\n",
    "model = ExtraTreesClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "model.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T16:02:47.699832Z",
     "start_time": "2018-07-16T16:02:47.475375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.5544211485870556\n",
      "test score: 0.4915486523526725\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T15:14:20.128282Z",
     "start_time": "2018-07-16T15:14:20.124206Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
